{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import save_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours_Studied</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Previous_Scores</th>\n",
       "      <th>Tutoring_Sessions</th>\n",
       "      <th>Exam_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>84</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>98</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>89</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>92</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>25</td>\n",
       "      <td>69</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>10</td>\n",
       "      <td>86</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>15</td>\n",
       "      <td>67</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6607 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hours_Studied  Attendance  Previous_Scores  Tutoring_Sessions  \\\n",
       "0                23          84               73                  0   \n",
       "1                19          64               59                  2   \n",
       "2                24          98               91                  2   \n",
       "3                29          89               98                  1   \n",
       "4                19          92               65                  3   \n",
       "...             ...         ...              ...                ...   \n",
       "6602             25          69               76                  1   \n",
       "6603             23          76               81                  3   \n",
       "6604             20          90               65                  3   \n",
       "6605             10          86               91                  2   \n",
       "6606             15          67               94                  0   \n",
       "\n",
       "      Exam_Score  \n",
       "0             67  \n",
       "1             61  \n",
       "2             74  \n",
       "3             71  \n",
       "4             70  \n",
       "...          ...  \n",
       "6602          68  \n",
       "6603          69  \n",
       "6604          68  \n",
       "6605          68  \n",
       "6606          64  \n",
       "\n",
       "[6607 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv('./StudentPerformanceFactors.csv')\n",
    "dat = dat[['Hours_Studied', 'Attendance', 'Previous_Scores', 'Tutoring_Sessions', 'Exam_Score']]\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "X, y = dat[['Hours_Studied', 'Attendance', 'Previous_Scores', 'Tutoring_Sessions']], dat[[ 'Exam_Score']]\n",
    "scaler = StandardScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test) #make sure not to leak information to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Degree: 1 , our Train MSE: 6.361797251640075, Test MSE: 5.069439258236875, Train R2: 0.5863849821854334, Test R2: 0.6413573918421556\n",
      "For Degree: 2 , our Train MSE: 6.348348076927452, Test MSE: 5.0844372801321684, Train R2: 0.5872593861342419, Test R2: 0.6402963416123896\n",
      "For Degree: 3 , our Train MSE: 6.318106445722766, Test MSE: 5.091288170780316, Train R2: 0.5892255589521894, Test R2: 0.6398116684236806\n",
      "For Degree: 4 , our Train MSE: 6.270753949026224, Test MSE: 5.156117061623398, Train R2: 0.5923042021390114, Test R2: 0.6352252829653352\n"
     ]
    }
   ],
   "source": [
    "# Polynomial Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "degrees = [1,2,3,4]\n",
    "for i in degrees:\n",
    "    poly = PolynomialFeatures(degree = i)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    y_train_pred = model.predict(X_train_poly)\n",
    "    y_test_pred = model.predict(X_test_poly)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    print(f'For Degree: {i} , our Train MSE: {train_mse}, Test MSE: {test_mse}, Train R2: {train_r2}, Test R2: {test_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/5j9xydr90s30r_9rw5pwhf640000gn/T/ipykernel_15845/3736052450.py:21: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, epochs=10, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'batch_size': 32, 'learning_rate': 0.001, 'momentum': 0.9, 'regularization': 0.0001}\n",
      "Best score:  -6.764690558115642\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 402.1486 - mse: 402.1483 - val_loss: 5.5854 - val_mse: 5.5852\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - 0s 663us/step - loss: 6.9919 - mse: 6.9917 - val_loss: 6.2699 - val_mse: 6.2697\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - 0s 631us/step - loss: 7.3501 - mse: 7.3499 - val_loss: 5.3129 - val_mse: 5.3127\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - 0s 629us/step - loss: 7.6702 - mse: 7.6700 - val_loss: 6.3625 - val_mse: 6.3623\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - 0s 642us/step - loss: 7.3449 - mse: 7.3447 - val_loss: 5.2635 - val_mse: 5.2633\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - 0s 637us/step - loss: 6.9220 - mse: 6.9218 - val_loss: 5.1265 - val_mse: 5.1263\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - 0s 608us/step - loss: 7.0007 - mse: 7.0005 - val_loss: 5.8556 - val_mse: 5.8554\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - 0s 611us/step - loss: 7.3684 - mse: 7.3682 - val_loss: 5.3835 - val_mse: 5.3833\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - 0s 608us/step - loss: 6.9276 - mse: 6.9275 - val_loss: 5.9613 - val_mse: 5.9611\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - 0s 673us/step - loss: 7.2390 - mse: 7.2388 - val_loss: 7.2889 - val_mse: 7.2887\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(2024)\n",
    "def create_model(learning_rate=0.001, regularization=0, momentum=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=tf.keras.regularizers.l2(regularization)))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "model = KerasRegressor(build_fn=create_model, epochs=10, verbose=0)\n",
    "param_grid = {\n",
    "    'batch_size': [16, 32],\n",
    "    'learning_rate': [0.001, 0.01],\n",
    "    'regularization': [0.001, 0.0001],\n",
    "    'momentum': [0.0, 0.9]\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid,n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \", grid_result.best_params_)\n",
    "print(\"Best score: \", grid_result.best_score_)\n",
    "\n",
    "#Rebuild model with best hyperparameters\n",
    "best_params = grid_result.best_params_\n",
    "best_model = create_model(learning_rate=best_params['learning_rate'],regularization=best_params['regularization'], momentum=best_params['momentum'])\n",
    "history = best_model.fit(X_train, y_train, epochs=10, batch_size=best_params['batch_size'], validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test MSE: 5.123589515686035\n",
      "Final Test RMSE: 2.263534739226689\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "final_test_mse = best_model.evaluate(X_test, y_test, verbose=0)[0]\n",
    "final_test_rmse = np.sqrt(final_test_mse)\n",
    "print(f\"Final Test MSE: {final_test_mse}\")\n",
    "print(f\"Final Test RMSE: {final_test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 960us/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "scatter() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Graph for actual vs predicted\u001b[39;00m\n\u001b[1;32m      2\u001b[0m y_pred \u001b[39m=\u001b[39m best_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m----> 3\u001b[0m plt\u001b[39m.\u001b[39;49mscatter(np\u001b[39m.\u001b[39;49marray(y_pred))\n\u001b[1;32m      4\u001b[0m \u001b[39m# plt.xlabel('Actual Grades')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# plt.ylabel('Predicted Grades')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# plt.title('Actual vs Predicted Grades')\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# plt.plot([0, 100], [0, 100], 'r--')  \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# plt.grid(True)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mTypeError\u001b[0m: scatter() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "# Graph for actual vs predicted\n",
    "y_pred = best_model.predict(X_test)\n",
    "plt.scatter(np.array(y_pred))\n",
    "# plt.xlabel('Actual Grades')\n",
    "# plt.ylabel('Predicted Grades')\n",
    "# plt.title('Actual vs Predicted Grades')\n",
    "# plt.plot([0, 100], [0, 100], 'r--')  \n",
    "# plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Insufficient precision in available types to represent (31, 23, 8, 0, 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m save_model(best_model, \u001b[39m'\u001b[39;49m\u001b[39mneuralnetwork.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ECS171/lib/python3.10/site-packages/keras/saving/saving_api.py:145\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     saving_lib\u001b[39m.\u001b[39msave_model(model, filepath)\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39m# Legacy case\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49msave_model(\n\u001b[1;32m    146\u001b[0m         model,\n\u001b[1;32m    147\u001b[0m         filepath,\n\u001b[1;32m    148\u001b[0m         overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[1;32m    149\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[1;32m    150\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    151\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/ECS171/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/ECS171/lib/python3.10/site-packages/h5py/_hl/dataset.py:887\u001b[0m, in \u001b[0;36mDataset.__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    883\u001b[0m args \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m args \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m))\n\u001b[1;32m    885\u001b[0m \u001b[39m# Generally we try to avoid converting the arrays on the Python\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39m# side.  However, for compound literals this is unavoidable.\u001b[39;00m\n\u001b[0;32m--> 887\u001b[0m vlen \u001b[39m=\u001b[39m h5t\u001b[39m.\u001b[39mcheck_vlen_dtype(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)\n\u001b[1;32m    888\u001b[0m \u001b[39mif\u001b[39;00m vlen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m vlen \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    889\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/ECS171/lib/python3.10/site-packages/h5py/_hl/dataset.py:563\u001b[0m, in \u001b[0;36mDataset.dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    560\u001b[0m \u001b[39m@with_phil\u001b[39m\n\u001b[1;32m    561\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdtype\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    562\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Numpy dtype representing the datatype\"\"\"\u001b[39;00m\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mid\u001b[39m.\u001b[39;49mdtype\n",
      "File \u001b[0;32mh5py/h5d.pyx:180\u001b[0m, in \u001b[0;36mh5py.h5d.DatasetID.dtype.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5d.pyx:183\u001b[0m, in \u001b[0;36mh5py.h5d.DatasetID.dtype.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:445\u001b[0m, in \u001b[0;36mh5py.h5t.TypeID.dtype.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:446\u001b[0m, in \u001b[0;36mh5py.h5t.TypeID.dtype.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:1087\u001b[0m, in \u001b[0;36mh5py.h5t.TypeFloatID.py_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Insufficient precision in available types to represent (31, 23, 8, 0, 23)"
     ]
    }
   ],
   "source": [
    "save_model(best_model, 'neuralnetwork.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: neuralnetwork/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: neuralnetwork/assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save('neuralnetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECS171",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24b1c6c62fc2ad10d47b0d0cef7c4fb98183c7281f59ee5b505c051375858564"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
